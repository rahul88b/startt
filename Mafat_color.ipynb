{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mafat-color.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahul88b/startt/blob/master/Mafat_color.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "d3jXhxSuWZNX",
        "colab_type": "code",
        "outputId": "e7b61e77-06c3-40e8-9fc1-7e2c63f0fbef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import csv\n",
        "import scipy.misc\n",
        "from scipy import ndimage\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "from sklearn import preprocessing\n",
        "from keras import layers\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Add, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D, Concatenate\n",
        "from keras.models import Model, load_model\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "\n",
        "\n",
        "from keras.initializers import glorot_uniform\n",
        "import scipy.misc\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "\n",
        "import keras.backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "K.set_learning_phase(1)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "eFYTCLa1ZwvB",
        "colab_type": "code",
        "outputId": "d8cae263-d043-406b-ca30-5aeef6b4564d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tW0yeSfrZxTo",
        "colab_type": "code",
        "outputId": "242f6376-679f-4aab-e217-fb5cc07456ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "with open('/content/gdrive/My Drive/foo.txt', 'w') as f:\n",
        "  f.write('Hello Google Drive!')\n",
        "!cat /content/gdrive/My\\ Drive/foo.txt"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello Google Drive!"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2K7MuvFJZC-n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(\"./gdrive/My Drive/mafat/train.csv\")\n",
        "train.set_index('image_id',inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8BBL5HEsbsRK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "image_size=64\n",
        "num_channels=3\n",
        "num_pictures=275\n",
        "train_dir=\"./gdrive/My Drive/mafat/training imagery/\"\n",
        "val_dir=\"./gdrive/My Drive/mafat/test imagery/\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "29DsHBE4GWad",
        "colab_type": "code",
        "outputId": "9b414197-b554-4ca1-eb1f-8e2efda2337f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "image_name=[]\n",
        "num_tiff=0\n",
        "for file in os.listdir(train_dir):\n",
        "  if file[-3:]!='jpg':\n",
        "    num_tiff=num_tiff+1\n",
        "    continue\n",
        "  image_name.append(file[:-4])\n",
        "print(num_tiff)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BPyLTloa3gtN",
        "colab_type": "code",
        "outputId": "ad85862e-3237-4412-c7ff-e4334ef6bf9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "total_pictures=len(image_name)\n",
        "total_pictures"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1583"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "OjkaXEbedrTR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#importing data\n",
        "\n",
        "def get_next_batch(image_index):\n",
        "  \n",
        "  images=np.ndarray(shape=(num_pictures,image_size,image_size,num_channels))\n",
        "  current_index=0\n",
        "  labels=[]\n",
        "  num_tiff=0\n",
        "\n",
        "  while current_index<num_pictures and image_index<total_pictures:\n",
        "    \n",
        "      file=image_name[image_index]\n",
        "    \n",
        "      image=os.path.join(train_dir,file+'.jpg')\n",
        "      file_data=mpimg.imread(image)\n",
        "      height=file_data.shape[0]\n",
        "      breadth=file_data.shape[1]\n",
        "    \n",
        "      image_id=np.ndarray(shape=(1),dtype='int32')\n",
        "      image_id=int(file)\n",
        "    \n",
        "    \n",
        "      lb=train.loc[image_id,['color']]\n",
        "      label_gate=0\n",
        "      if(lb.shape[0]==1):\n",
        "          lb=lb.values\n",
        "          label_gate=1\n",
        "      else:\n",
        "          lb=lb['color'].tolist()\n",
        "    \n",
        "    \n",
        "      bb=train.loc[image_id,['p1_x','p_1y',' p2_x',' p2_y',' p3_x',' p3_y',' p4_x',' p4_y']].values\n",
        "      n=bb.shape[0]\n",
        "      if len(bb.shape)==1:\n",
        "        box=np.ndarray(shape=(1,8))\n",
        "        box[0,:]=bb[0]\n",
        "        bb=box\n",
        "        n=1\n",
        "    \n",
        "      box=np.ndarray(shape=(n,4))\n",
        "      for i in range(n):\n",
        "        x1=min(bb[i,0],bb[i,2],bb[i,4],bb[i,6])\n",
        "        x2=max(bb[i,0],bb[i,2],bb[i,4],bb[i,6])\n",
        "        y1=min(bb[i,1],bb[i,3],bb[i,5],bb[i,7])\n",
        "        y2=max(bb[i,1],bb[i,3],bb[i,5],bb[i,7])\n",
        "        box[i,0]=y1/height\n",
        "        box[i,1]=x1/breadth\n",
        "        box[i,2]=y2/height\n",
        "        box[i,3]=x2/breadth\n",
        "        y=np.ndarray(shape=(1,file_data.shape[0],file_data.shape[1],3))\n",
        "        y[0,:,:,:]=file_data[:,:,0:3]\n",
        "   \n",
        "      cropped=tf.image.crop_and_resize(image=y,boxes=box,box_ind=[0]*box.shape[0],crop_size=[image_size,image_size],method='bilinear')\n",
        "      sess=tf.Session()\n",
        "      with sess.as_default():\n",
        "          tensor=cropped\n",
        "          cropped=tensor.eval()\n",
        "      n=cropped.shape[0]\n",
        "    \n",
        "    \n",
        "      for i in range(n):\n",
        "          images[current_index,:,:,:]=cropped[i,:,:,:]\n",
        "          \n",
        "          current_index=current_index+1\n",
        "          if label_gate==0:\n",
        "            labels.append(lb[i])\n",
        "          else:\n",
        "            labels.extend(lb)\n",
        "\n",
        "          if current_index>=num_pictures:\n",
        "            break\n",
        "      image_index=image_index+1\n",
        "  \n",
        "  labels=np.asarray(labels)\n",
        "  #shuffling data\n",
        "\n",
        "  random=np.arange(num_pictures)\n",
        "  np.random.shuffle(random)\n",
        "  images=images[random]\n",
        "  labels=labels[random]\n",
        "  \n",
        "  \n",
        "  return images[:250,:,:,:],labels[:250],image_index,images[250:,:,:,:],labels[250:]\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EHM5jvYAsWTb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "all_labels=train['color'].values\n",
        "all_labels=np.asarray(all_labels)\n",
        "le = preprocessing.LabelEncoder()\n",
        "training_le = le.fit(all_labels)\n",
        "num_classes=le.classes_.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qp6Z-mnxtIOV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_encoded_label(labels,val_y):\n",
        "  return training_le.transform(labels),training_le.transform(val_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zw5gjgAmtsc_",
        "colab_type": "code",
        "outputId": "f69c2eb9-1b91-4c92-f1ab-c9ba45519bb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "le.classes_"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['black', 'blue', 'green', 'other', 'red', 'silver/grey', 'white',\n",
              "       'yellow'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "SADng8a-uwle",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def identity_block(X, f, filters):\n",
        "    \n",
        "    F1, F2, F3 = filters\n",
        "     \n",
        "    X_shortcut = X\n",
        "   \n",
        "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3)(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    X = Conv2D(filters=F2,kernel_size=(f,f),strides=(1,1),padding='same',kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3)(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    X = X = Conv2D(filters=F3,kernel_size=(1,1),strides=(1,1),padding='valid',kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3)(X)\n",
        "\n",
        "    X = layers.Add()([X,X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xyE87DJowYKN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def convolutional_block(X, f, filters,s = 2):\n",
        "    \n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    X_shortcut = X\n",
        "\n",
        "    X = Conv2D(F1, (1, 1), strides = (s,s), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3)(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    X = Conv2D(F2,(f,f),strides=(1,1),padding='same',kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3)(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    X = Conv2D(F3,(1,1),strides=(1,1),padding='valid',kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3)(X)\n",
        "\n",
        "    X_shortcut = Conv2D(F3,(1,1),strides=(s,s),padding='valid',kernel_initializer=glorot_uniform(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis=3)(X_shortcut)\n",
        "\n",
        "    X = layers.Add()([X,X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "    return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Tre9xs0nw4Oc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def ResNet50(input_shape, classes):\n",
        "    \n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "    \n",
        "    X = Conv2D(64, (7, 7), strides = (2, 2), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3)(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], s = 1)\n",
        "    X = identity_block(X, 3, [64, 64, 256])\n",
        "    X = identity_block(X, 3, [64, 64, 256])\n",
        "\n",
        "    X = convolutional_block(X,f=3,filters=[128,128,512],s=2)\n",
        "    X = identity_block(X,3,[128,128,512])\n",
        "    X = identity_block(X,3,[128,128,512])\n",
        "    X = identity_block(X,3,[128,128,512])\n",
        "\n",
        "    X = convolutional_block(X,f=3,filters=[256,256,1024],s=2)\n",
        "    X = identity_block(X,3,[256,256,1024])\n",
        "    X = identity_block(X,3,[256,256,1024])\n",
        "    X = identity_block(X,3,[256,256,1024])\n",
        "    X = identity_block(X,3,[256,256,1024])\n",
        "    X = identity_block(X,3,[256,256,1024])\n",
        "\n",
        "    X = convolutional_block(X,f=3,filters=[512,512,2048],s=2)\n",
        "    X = identity_block(X,3,[512,512,2048])\n",
        "    X = identity_block(X,3,[512,512,2048])\n",
        "\n",
        "    X = AveragePooling2D((2,2))(X)\n",
        "    \n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation='softmax', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    model = Model(inputs = X_input, outputs = X)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lr2S2edrxo9u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = ResNet50(input_shape = (image_size, image_size, 3), classes=num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GRBTV99ux7b_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sI0lGsaXyM6E",
        "colab_type": "code",
        "outputId": "12322e28-111b-42f4-8992-4abf4dc1b5af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1241
        }
      },
      "cell_type": "code",
      "source": [
        "num_times=8\n",
        "image_index=0\n",
        "X_val=np.ndarray(shape=(0,image_size,image_size,num_channels))\n",
        "Y_val=np.ndarray(shape=(0))\n",
        "\n",
        "for i in range(num_times):\n",
        "  \n",
        "  X,labels,image_index,val_x,val_y=get_next_batch(image_index)\n",
        "  print('image_index',image_index)\n",
        "  Y,val_y=get_encoded_label(labels,val_y)\n",
        "  X_val=np.concatenate((X_val,val_x), axis=0)\n",
        "  Y_val=np.concatenate((Y_val,val_y), axis=0)\n",
        "  model.fit(X, Y, epochs = 4, batch_size = 32)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "image_index 63\n",
            "Epoch 1/4\n",
            "250/250 [==============================] - 13s 51ms/step - loss: 3.2650 - acc: 0.2440\n",
            "Epoch 2/4\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 1.4876 - acc: 0.5320\n",
            "Epoch 3/4\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 1.2319 - acc: 0.5480\n",
            "Epoch 4/4\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 1.1365 - acc: 0.6080\n",
            "image_index 131\n",
            "Epoch 1/4\n",
            "250/250 [==============================] - 3s 12ms/step - loss: 1.6281 - acc: 0.4920\n",
            "Epoch 2/4\n",
            "250/250 [==============================] - 2s 9ms/step - loss: 1.3895 - acc: 0.5960\n",
            "Epoch 3/4\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 1.2764 - acc: 0.6800\n",
            "Epoch 4/4\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 1.0937 - acc: 0.7320\n",
            "image_index 183\n",
            "Epoch 1/4\n",
            "250/250 [==============================] - 2s 9ms/step - loss: 1.7729 - acc: 0.5280\n",
            "Epoch 2/4\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 1.5691 - acc: 0.5840\n",
            "Epoch 3/4\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 1.4988 - acc: 0.6120\n",
            "Epoch 4/4\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 1.3156 - acc: 0.6800\n",
            "image_index 231\n",
            "Epoch 1/4\n",
            "250/250 [==============================] - 3s 12ms/step - loss: 1.5784 - acc: 0.5800\n",
            "Epoch 2/4\n",
            "250/250 [==============================] - 2s 9ms/step - loss: 1.4325 - acc: 0.7040\n",
            "Epoch 3/4\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 1.1532 - acc: 0.7280\n",
            "Epoch 4/4\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 1.1615 - acc: 0.7800\n",
            "image_index 275\n",
            "Epoch 1/4\n",
            "250/250 [==============================] - 3s 12ms/step - loss: 1.6354 - acc: 0.6400\n",
            "Epoch 2/4\n",
            "250/250 [==============================] - 2s 9ms/step - loss: 1.3894 - acc: 0.6200\n",
            "Epoch 3/4\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 1.3404 - acc: 0.6880\n",
            "Epoch 4/4\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 1.7974 - acc: 0.6560\n",
            "image_index 317\n",
            "Epoch 1/4\n",
            "250/250 [==============================] - 2s 9ms/step - loss: 1.6168 - acc: 0.5360\n",
            "Epoch 2/4\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 1.4711 - acc: 0.5200\n",
            "Epoch 3/4\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 1.2874 - acc: 0.6640\n",
            "Epoch 4/4\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 1.2648 - acc: 0.7360\n",
            "image_index 368\n",
            "Epoch 1/4\n",
            "250/250 [==============================] - 3s 11ms/step - loss: 1.3202 - acc: 0.5760\n",
            "Epoch 2/4\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 1.3037 - acc: 0.6720\n",
            "Epoch 3/4\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 1.3026 - acc: 0.6840\n",
            "Epoch 4/4\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.9151 - acc: 0.7280\n",
            "image_index 432\n",
            "Epoch 1/4\n",
            "250/250 [==============================] - 3s 12ms/step - loss: 1.7871 - acc: 0.5400\n",
            "Epoch 2/4\n",
            "250/250 [==============================] - 2s 10ms/step - loss: 1.6987 - acc: 0.6040\n",
            "Epoch 3/4\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 1.2600 - acc: 0.6680\n",
            "Epoch 4/4\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 1.5497 - acc: 0.6200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "w4Bp7TIuyTTz",
        "colab_type": "code",
        "outputId": "5bd4a206-eb62-4de9-a3fa-9a9411c33257",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "val_set = model.evaluate(X_val, Y_val)\n",
        "print (\"Loss = \" + str(val_set[0]))\n",
        "print (\"Test Accuracy = \" + str(val_set[1]))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200/200 [==============================] - 2s 9ms/step\n",
            "Loss = 1.787266550064087\n",
            "Test Accuracy = 0.615\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "de8eLH_qGCXQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save(\"./gdrive/My Drive/mafat/color/model_color\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZKemxM2tGzxb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model=load_model(\"./gdrive/My Drive/mafat/color/model_color\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1sWdtR_WATPK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save(\"./gdrive/My Drive/mafat/color/MyModel_color\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zjgAxYsyN9CP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}